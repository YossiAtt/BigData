{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(142, 'dfdf'), (142, 'vaniqa.comh'), (142, '207 ad2d 530'), (142, 'attornyleslie.com'), (217, 'mizuno.com'), (217, \"p; .; p;' p; ' ;' ;';\"), (217, 'yahoo.com'), (1268, 'sstack.com'), (1268, 'www.raindanceexpress.com'), (1326, 'files')]\n"
     ]
    }
   ],
   "source": [
    "SUPPORT_TRASHOLD=0.0005\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import Row\n",
    "import time\n",
    "import re\n",
    "\n",
    "def removeTimestamp(row):\n",
    "    find = re.compile(r'\\d{4}-\\d{2}-\\d{2}')\n",
    "    start = re.search(find,row).start()\n",
    "    return row[0:start]\n",
    "\n",
    "def spliteToUserIdAndUserSearch(row):\n",
    "    row = row.split(\"\\t\", 1)\n",
    "    row[1] =  row[1].rstrip('\\t')\n",
    "    return (int(row[0]),row[1])\n",
    "\n",
    "def uniqueList(line):\n",
    "    uniqueSearches = set(line[1])\n",
    "    newLine = [line[0],list(uniqueSearches)]\n",
    "    return newLine\n",
    "\n",
    "start = time.time()\n",
    "log_txt=sc.textFile(\"user-searches.txt\")\n",
    "header = log_txt.first()\n",
    "\n",
    "\n",
    "log_txt = log_txt.filter(lambda line: line != header)\n",
    "logSearch = log_txt.map(lambda line: spliteToUserIdAndUserSearch(removeTimestamp(line))).filter(lambda line: line[1] !='-').distinct()\n",
    "\n",
    "print(logSearch.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalOfTransactions = logSearch.groupByKey().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64942\n"
     ]
    }
   ],
   "source": [
    "print(totalOfTransactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('craiglist', 0.0007853161282375043),\n",
       " ('.com', 0.017076776200301808),\n",
       " ('sprint.com', 0.0019247944319546672),\n",
       " ('www.google', 0.010255304733454467),\n",
       " ('msnbc.com', 0.0005851375073142189),\n",
       " ('y', 0.005112254011271597),\n",
       " ('usps.com', 0.0017862092328539312),\n",
       " ('travelocity', 0.007452804040528472),\n",
       " ('ww.yahoo.com', 0.0005235440854916695),\n",
       " ('best buy', 0.006174740537710573)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the user id -> return only query \n",
    "all_queries = logSearch.map(lambda line: line[1])\n",
    "# count how much time query is show for all the user divide by number of users\n",
    "rdd_query_count = all_queries.map(lambda q: (q, 1) ).reduceByKey(lambda c1,c2: c1+c2 ) \\\n",
    "                                                    .map(lambda x: (x[0], x[1] / totalOfTransactions)) \\\n",
    "                                                    .filter(lambda x: (x[1] > SUPPORT_TRASHOLD))\n",
    "\n",
    "# rdd_query_count is list of queries that pass the thrasholds of support\n",
    "rdd_query_count.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(382200, ['.com', 'american greetings', 'www.google.com', 'dictionary', 'www.comcast.net']), (1648038, ['.com', 'google.com', 'target', 'http', 'old navy', 'good morning america', 'ebay.com', 'song lyrics', 'dictionary.com', 'currency converter', 'oldnavy.com', 'myspace', 'wachovia', 'www.myspace.com', 'yahoo', 'google', 'universal studios', 'delta airlines', 'myspac', 'myspace.com', 'prom dresses', 'oriental trading company'])]\n"
     ]
    }
   ],
   "source": [
    "user_query = logSearch.map(lambda x: (x[1],x[0]))\n",
    "tupleWordAfterTrashold = user_query.join(rdd_query_count)\n",
    "user_query = tupleWordAfterTrashold.map(lambda x: (x[1][0],x[0]))\n",
    "user_query = user_query.groupByKey().mapValues(list).filter(lambda kv: len(kv[1]) > 1) \n",
    "print(user_query.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.com', 'american greetings'),\n",
       " ('.com', 'www.google.com'),\n",
       " ('.com', 'dictionary'),\n",
       " ('.com', 'www.comcast.net'),\n",
       " ('american greetings', 'www.google.com'),\n",
       " ('american greetings', 'dictionary'),\n",
       " ('american greetings', 'www.comcast.net'),\n",
       " ('www.google.com', 'dictionary'),\n",
       " ('www.google.com', 'www.comcast.net'),\n",
       " ('dictionary', 'www.comcast.net'),\n",
       " ('.com', 'google.com'),\n",
       " ('.com', 'target'),\n",
       " ('.com', 'http'),\n",
       " ('.com', 'old navy'),\n",
       " ('.com', 'good morning america'),\n",
       " ('.com', 'ebay.com'),\n",
       " ('.com', 'song lyrics'),\n",
       " ('.com', 'dictionary.com'),\n",
       " ('.com', 'currency converter'),\n",
       " ('.com', 'oldnavy.com'),\n",
       " ('.com', 'myspace'),\n",
       " ('.com', 'wachovia'),\n",
       " ('.com', 'www.myspace.com'),\n",
       " ('.com', 'yahoo'),\n",
       " ('.com', 'google'),\n",
       " ('.com', 'universal studios'),\n",
       " ('.com', 'delta airlines'),\n",
       " ('.com', 'myspac'),\n",
       " ('.com', 'myspace.com'),\n",
       " ('.com', 'prom dresses'),\n",
       " ('.com', 'oriental trading company'),\n",
       " ('google.com', 'target'),\n",
       " ('google.com', 'http'),\n",
       " ('google.com', 'old navy'),\n",
       " ('google.com', 'good morning america'),\n",
       " ('google.com', 'ebay.com'),\n",
       " ('google.com', 'song lyrics'),\n",
       " ('google.com', 'dictionary.com'),\n",
       " ('google.com', 'currency converter'),\n",
       " ('google.com', 'oldnavy.com'),\n",
       " ('google.com', 'myspace'),\n",
       " ('google.com', 'wachovia'),\n",
       " ('google.com', 'www.myspace.com'),\n",
       " ('google.com', 'yahoo'),\n",
       " ('google.com', 'google'),\n",
       " ('google.com', 'universal studios'),\n",
       " ('google.com', 'delta airlines'),\n",
       " ('google.com', 'myspac'),\n",
       " ('google.com', 'myspace.com'),\n",
       " ('google.com', 'prom dresses')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_pairs(arr):\n",
    "        result = []\n",
    "        for p1 in range(len(arr)):\n",
    "                for p2 in range(p1+1,len(arr)):\n",
    "                        result.append((arr[p1],arr[p2]))\n",
    "        return result\n",
    "    \n",
    "all_queries_pairs_tuples = user_query.map(lambda kv: kv[1]).flatMap(lambda arr: get_all_pairs(arr))\n",
    "all_queries_pairs_tuples.take(50)\n",
    "# userId | a, b ,c ,d\n",
    "# 1| 1,1,0,0->a,b\n",
    "# 2|0,1,1,0->b,c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('american greetings', 'dictionary'), 9.239013273382403e-05),\n",
       " (('.com', 'myspac'), 6.159342182254935e-05),\n",
       " (('old navy', 'universal studios'), 3.0796710911274674e-05),\n",
       " (('good morning america', 'prom dresses'), 3.0796710911274674e-05),\n",
       " (('myspace', 'yahoo'), 0.0032182562902282035),\n",
       " (('google', 'myspac'), 0.00016938191001201073),\n",
       " (('delta airlines', 'prom dresses'), 3.0796710911274674e-05),\n",
       " (('bank of america', 'delta.com'), 4.6195066366912014e-05),\n",
       " (('amtrak', 'delta.com'), 4.6195066366912014e-05),\n",
       " (('amtrak', 'bank of america'), 0.00010778848818946137)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sort_small_list(arr):\n",
    "    if(arr[0] <= arr[1]):\n",
    "        return arr\n",
    "    return [arr[1],arr[0]]\n",
    "# the sort is for (a,b) (b,a) = > (a,b) (a,b) => ((a,b),2)\n",
    "all_queries_tuples_sorted = all_queries_pairs_tuples.map(lambda kv: sort_small_list(list(kv))) \\\n",
    "                                                .map(lambda arr: (arr[0],arr[1]) )\n",
    "\n",
    "all_queries_pairs_tuples_count = all_queries_tuples_sorted.map(lambda kv: (kv,1)) \\\n",
    "                                                    .reduceByKey(lambda c1,c2: c1+c2 )\\\n",
    "                                                    .filter(lambda kv: kv[1] > 1) \\\n",
    "                                                    .map(lambda x: (x[0], x[1] / totalOfTransactions)) \n",
    "\n",
    "\n",
    "all_queries_pairs_tuples_count.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((('american greetings', 'dictionary'), 9.239013273382403e-05),\n",
       "  ('craiglist', 0.0007853161282375043)),\n",
       " ((('american greetings', 'dictionary'), 9.239013273382403e-05),\n",
       "  ('.com', 0.017076776200301808)),\n",
       " ((('american greetings', 'dictionary'), 9.239013273382403e-05),\n",
       "  ('sprint.com', 0.0019247944319546672))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_queries_tuples_cartesian = all_queries_pairs_tuples_count.cartesian(rdd_query_count)\n",
    "rdd_queries_tuples_cartesian.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this command calculate XUY/X by taking all lines that ((x ,y , number of suply(xUy)),(z ,number of suply(z))) when z ==x\n",
    "rdd_join_left = rdd_queries_tuples_cartesian.filter(lambda lr: lr[0][0][0] == lr[1][0]) \\\n",
    "                                            .map(lambda lr: (lr[0][0][0],lr[0][0][1],float(lr[0][1]) / lr[1][1]))\n",
    "rdd_join_left = rdd_join_left.filter(lambda confidance: confidance[2]>0.6)\n",
    "print(rdd_join_left.take(5))\n",
    "# this command take XUY/Y\n",
    "\n",
    "rdd_join_right = rdd_queries_tuples_cartesian.filter(lambda lr: lr[0][0][1] == lr[1][0])\\\n",
    "                                             .map(lambda lr: (lr[0][0][1], lr[0][0][0], float(lr[0][1]) / lr[1][1]))\n",
    "\n",
    "rdd_join_right = rdd_join_right.filter(lambda confidance: confidance[2]>0.6)\n",
    "\n",
    "print(rdd_join_right.take(5))\n",
    "\n",
    "rdd_query_conf = sc.union([rdd_join_left, rdd_join_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "####### TASK 1 ########\n",
    "#######################\n",
    "\n",
    "x_y_conf06 = sc.union([rdd_join_left, rdd_join_right])\n",
    "print(x_y_conf06.take(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "####### TASK 2  #######\n",
    "#######################\n",
    "rddQueryConfDF = sqlContext.createDataFrame(x_y_conf06, [\"X\", \"Y\",\"CONFIDENCE\"])\n",
    "rddQueryConfDF.coalesce(1).write.format('com.databricks.spark.csv').save('./my.csv',header = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(end - start))\n",
    "print(\"elapsed time: %s\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "####### TASK 4.a ########\n",
    "#########################\n",
    "rdd_query_conf_Temp = sc.textFile(\"my.csv\")\n",
    "headerConf = rdd_query_conf_Temp.first()\n",
    "x_y_conf06 = rdd_query_conf_Temp.filter(lambda line: line != headerConf)\\\n",
    "                                                        .map(lambda x: x.split(','))\\\n",
    "                                                        .map(lambda x: (x[0],x[1],float(x[2])))\n",
    "\n",
    "x_y_conf06.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterConfidence(line,Conf):\n",
    "    if line[2] >=Conf:\n",
    "        return(True)\n",
    "    return(False)\n",
    "\n",
    "x_y_conf08 = x_y_conf06.filter(lambda line: filterConfidence(line,0.8))\n",
    "x_y_conf09 = x_y_conf08.filter(lambda line: filterConfidence(line,0.9))\n",
    "print('the amount of related queries for 0.6 confidence')\n",
    "print(x_y_conf06.count())\n",
    "\n",
    "print('the amount of related queries for 0.8 confidence')\n",
    "print(x_y_conf08.count())\n",
    "\n",
    "print('the amount of related queries for 0.9 confidence')\n",
    "print(x_y_conf09.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempConfUp06 = x_y_conf06.map(lambda x: (x[2],(x[0],x[1])))\n",
    "\n",
    "sortTempConfUp06 = tempConfUp06.sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sortTempConfUp06.top(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
